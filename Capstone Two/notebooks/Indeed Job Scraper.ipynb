{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a general purpose job scraper for www.indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_search_url(position, postedDays):\n",
    "    \"\"\"Generate a url from position and posted days ago\"\"\"\n",
    "\n",
    "    template = 'https://www.indeed.com/jobs?q={}&fromage={}'\n",
    "    url=template.format(position, postedDays)\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_job_search_url('machine learning', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Extract raw html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page 1 of 198 jobs'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_jobs = soup.find('div',{'id':'searchCountPages'}).text.strip()\n",
    "total_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = soup.find_all('div', 'jobsearch-SerpJobCard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype the model with a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "card = cards[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "aTag = card.h2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = aTag.get('title')\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2a073aaa41c0c83f'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_id = card.get('data-jk')\n",
    "job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(60)\n",
    "job_url = 'https://www.indeed.com' + aTag.get('href')\n",
    "job_url\n",
    "\n",
    "post_response = requests.get(job_url)\n",
    "post_soup = BeautifulSoup(post_response.text, 'html.parser')\n",
    "job_description = post_soup.find('div','jobsearch-jobDescriptionText').text.strip()\n",
    "job_description\n",
    "\n",
    "try:\n",
    "    job_detail = post_soup.find('div','jobsearch-JobDescriptionSection-section').text.strip()\n",
    "except:\n",
    "    job_detail = ''\n",
    "job_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tradeweb is looking to add a Data Scientist to its Data & Analytics team. Our Data Science team is responsible for managing the development and optimization of advanced analytics on a global scale across the company.\\nIn this role, you will enjoy working with one of the richest financial data sets in the world, cutting edge technology, and the ability to see your insights turned into real products on a regular basis. The ideal candidate will have experience doing advanced data analysis, will have worked with large data stores, and will have experience building machine learning models. Candidates should be curious, focused on results, a self-starter, and have demonstrated success in using analytics to drive value in an organization.\\nDesign, build, test and deliver new data science services and advanced analytics to Tradeweb globally\\nDevelop scalable tools leveraging machine learning and/or deep learning models to solve real-world problems in areas such as time series predictions\\nSuggest, collect and synthesize requirements to create an effective roadmap towards the deployment of production-level machine learning applications\\nMaintain, improve and deliver innovations to the existing data products used\\nInvestigate ad hoc issues and debugging regressions\\nContribute to testing plans and validate statistically accurate results\\nAnalyze data trends to identify opportunities for growth\\nPartner with Data Engineering to ensure the right metrics are created and validate accuracy\\nValidate metric accuracy for internal and external reporting\\nMinimum Qualifications:\\nMasterâ€™s Degree or PhD in a quantitative field (Computer Science, Data Science, Statistics, Operations Research, Machine Learning or Economics) or equivalent work experience\\n3+ years of experience working in data science at a financial, technology or media firm\\nSignificant experience and expertise with probability and statistics, inclusive of machine learning, experimental design, and optimization\\nHighly skilled in scripting languages and have rapid prototyping skills, like SQL, Python, Perl, Java, among others\\nTeam builder, results oriented, and proactive\\nAbout Tradeweb:\\nTradeweb Markets Inc. (NASDAQ: TW) is a leading, global operator of electronic marketplaces for rates, credit, equities and money markets. Founded in 1996, Tradeweb provides access to markets, data and analytics, electronic trading, straight-through-processing and reporting for clients in the institutional, wholesale and retail markets. Advanced technologies developed by Tradeweb enhance price discovery, order execution and trade workflows while allowing for greater scale and helping to reduce risks in client trading operations. For more information, please go to www.tradeweb.com .\\nTradeweb Markets LLC (\"Tradeweb\") is proud to be an EEO Minorities/Females/Protected Veterans/Disabled/Affirmative Action Employer.\\nhttps://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oxford Global Resources'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_company = card.find('span','company').text.strip()\n",
    "job_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    company_rating = card.find('span','ratingsContent').text.strip()\n",
    "except AttributeError:\n",
    "    company_rating = ''\n",
    "company_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remote'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_location = card.find('div', 'recJobLoc').get('data-rc-loc')\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scientists will participate in data model development and petabyte-level data process optimization.\\nSome experience in big data processing.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_summary = card.find('div', 'summary').text.strip()\n",
    "job_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_post_date = card.find('span','date').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today().strftime('%Y-%m-%d') # To do: need to add time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021_02_14_20_13_19'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today().strftime('%Y_%m_%d_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 2, 14, 20, 13, 19, 452396)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    job_salary = card.find('span','salaryText').text.strip()\n",
    "except AttributeError:\n",
    "    job_salary = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    job_remote = card.find('span','remote').text.strip()\n",
    "except AttributeError:\n",
    "    job_remote = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalize the model with a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(card):\n",
    "    \"\"\"Extract individual job post data from a single record \"\"\"\n",
    "    # required variables\n",
    "    job_id = card.get('data-jk')\n",
    "    aTag = card.h2.a\n",
    "    job_title = aTag.get('title')\n",
    "    \n",
    "    job_url = 'https://www.indeed.com' + aTag.get('href')\n",
    "    #job_url = 'https://www.indeed.com/viewjob?jk=' + job_id\n",
    "    post_response = requests.get(job_url)\n",
    "    post_soup = BeautifulSoup(post_response.text, 'html.parser')\n",
    "    try:\n",
    "        job_description = post_soup.find('div','jobsearch-jobDescriptionText').text.strip()\n",
    "    except AttributeError:\n",
    "        job_description = ''\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        job_detail = post_soup.find('div','jobsearch-JobDescriptionSection-section').text.strip()\n",
    "    except AttributeError:\n",
    "        job_detail = ''\n",
    "    \n",
    "    job_company = card.find('span','company').text.strip()\n",
    "    job_location = card.find('div', 'recJobLoc').get('data-rc-loc')\n",
    "    job_summary = card.find('div', 'summary').text.strip()\n",
    "    job_post_date = card.find('span','date').text.strip()\n",
    "    \n",
    "    # optional variables\n",
    "    try:\n",
    "        company_rating = card.find('span','ratingsContent').text.strip()\n",
    "    except AttributeError:\n",
    "        company_rating = ''\n",
    "    \n",
    "    try:\n",
    "        job_salary = card.find('span','salaryText').text.strip()\n",
    "    except AttributeError:\n",
    "        job_salary = ''\n",
    "    \n",
    "    try:\n",
    "        job_remote = card.find('span','remote').text.strip()\n",
    "    except AttributeError:\n",
    "        job_remote = ''\n",
    "        \n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    record = (job_id, job_title,job_company,job_location,company_rating, job_post_date,today,job_summary,job_salary, job_remote, job_url, job_description, job_detail)\n",
    "    \n",
    "    return record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for card in cards:\n",
    "    record = get_record(card)\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1260f89ca0cbf7d8',\n",
       " 'Data Scientist',\n",
       " 'LoadSpring Solutions, Inc',\n",
       " 'Remote',\n",
       " '2.3',\n",
       " '5 days ago',\n",
       " '2021-02-14',\n",
       " 'Participate in data strategy and infrastructure discussions, help define requirements for data structures and data retention.',\n",
       " '',\n",
       " '',\n",
       " 'https://www.indeed.com/rc/clk?jk=1260f89ca0cbf7d8&fccid=a39f5e8cf0ebec8c&vjs=3',\n",
       " 'Are you a Data Scientist who prospers when they can evaluate and improve customersâ€™ products and help them drive their business goals with data? At LoadSpring, youâ€™ll work with large, complex data sets to solve difficult, non-routine analysis problems, and apply advanced analytical methods. You will build and deploy ML models for predictive insights and collaborate extensively with product managers, other data engineers, and UI/UX designers to bring your creations to life! If this excites you then we want to meet you!\\nThe Data Scientist Position\\nArticulate and translate business questions and using statistical techniques to arrive at answers using available data\\nAdept at executing every stage of the ML development lifecycle in a business setting; from initial requirements gathering through final model deployment, including iterative measurement and improvement\\nEnhancing data collection procedures to include information that is relevant for building analytic systems\\nWork with large volumes of structured and unstructured data from multiple data sources and can design and implement data pipelines to clean and merge these data for research and modeling\\nProcessing, cleansing, and verifying the integrity of data used for analysis\\nApplying experience with machine learning on large datasets\\nParticipate in data strategy and infrastructure discussions, help define requirements for data structures and data retention\\nQualifications\\nMinimum of a BS/BA with a concentration in quantitative discipline - Stats, Math, Comp Sci, Engineering, or similar discipline\\n3+ yearsâ€™ professional data science experience\\nDemonstrated experience building and deploying AI / Machine Learning solutions, at scale\\nExperience with relevant Project software and database languages is a plus\\nWorld-Class Benefits:\\nWe are proud of our high-energy and all-around fun working environment. Our team loves to come to work, loves to learn, and loves to win.\\nWe offer the following perks to keep you happy, healthy, and engaged at work\\nInvestment in your cultural development by paying for you to take vacations abroad!\\nAn entrepreneurial culture where employees are empowered, leadership is open, and your ideas are executed\\nA spot where executives are your partners who encourage innovation and your growth\\nAn entire company passionate about our cloud, technology, and top-notch customer service\\nA place where collaboration is highly valuable and all our employees feel like they sit in the office!\\nAs well as the usual benefits: Health, Dental, Vision, Life, 401k with a match, Tuition Reimbursement, and more!\\nEEO:\\nLoadSpring Solutions Inc. is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, or protected Veteran status.\\nU.S. Citizenship or Lawful Permanent Residence status may be required for certain positions. For positions requiring U.S. Citizenship or Lawful Permanent Resident status, verification of such status will be required upon accepting employment.\\nPRIVACY\\nYour privacy is very important to us, for more information on how we protect your information please visit: https://www.loadspring.com/privacy-statement/.\\nPowered by JazzHR\\nrGhdKbtR1E',\n",
       " '')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the next page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>hCaptcha solve page</title>\n",
       "<script async=\"\" defer=\"\" src=\"https://www.hcaptcha.com/1/api.js\"></script>\n",
       "</head>\n",
       "<body>\n",
       "<form action=\"/jobs?q=machine+learning&amp;fromage=1&amp;start=120\" method=\"POST\">\n",
       "<div class=\"h-captcha\" data-sitekey=\"eb27f525-f936-43b4-91e2-95a426d4a8bd\"></div>\n",
       "<br/>\n",
       "<input type=\"submit\" value=\"Submit\"/>\n",
       "</form>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=machine learning&fromage=1\n",
      "https://www.indeed.com/jobs?q=machine learning&fromage=1\n",
      "15\n",
      "https://www.indeed.com/jobs?q=machine+learning&fromage=1&start=10\n",
      "15\n",
      "https://www.indeed.com/jobs?q=machine+learning&fromage=1&start=20\n",
      "15\n",
      "https://www.indeed.com/jobs?q=machine+learning&fromage=1&start=30\n",
      "15\n",
      "https://www.indeed.com/jobs?q=machine+learning&fromage=1&start=40\n",
      "15\n",
      "https://www.indeed.com/jobs?q=machine+learning&fromage=1&start=50\n",
      "15\n",
      "https://www.indeed.com/jobs?q=machine+learning&fromage=1&start=60\n",
      "15\n",
      "https://www.indeed.com/jobs?q=machine+learning&fromage=1&start=70\n",
      "15\n",
      "https://www.indeed.com/jobs?q=machine+learning&fromage=1&start=80\n",
      "15\n",
      "https://www.indeed.com/jobs?q=machine+learning&fromage=1&start=90\n",
      "15\n",
      "https://www.indeed.com/jobs?q=machine+learning&fromage=1&start=100\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "records =[]\n",
    "url = get_job_search_url('machine learning', 1)\n",
    "print( url )\n",
    "while True:\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')   \n",
    "    cards = soup.find_all('div', 'jobsearch-SerpJobCard')\n",
    "    print(len(cards))\n",
    " \n",
    "    '''for card in cards:\n",
    "        record = get_record(card)\n",
    "        records.append(record)\n",
    "        time.sleep(3)\n",
    "\n",
    "print(len(records))'''\n",
    "    if len(cards)> 0:\n",
    "        try:\n",
    "            url = 'https://www.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href')\n",
    "        except AttributeError:\n",
    "            total_jobs = soup.find('div',{'id':'searchCountPages'}).text.strip()\n",
    "            print(url)\n",
    "            print(total_jobs)\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    else: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-cb4ebf620f7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'aria-label'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Next'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "soup.find('a', {'aria-label': 'Next'}).get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def get_job_search_url(position, postedDays):\n",
    "    \"\"\"Generate a url from position and posted days ago\"\"\"\n",
    "\n",
    "    template = 'https://www.indeed.com/jobs?q={}&fromage={}&limit=50'\n",
    "    url=template.format(position, postedDays)\n",
    "    \n",
    "    return url\n",
    "\n",
    "def get_record(card):\n",
    "    \"\"\"Extract individual job post data from a single record \"\"\"\n",
    "    # required variables\n",
    "    job_id = card.get('data-jk')\n",
    "    aTag = card.h2.a\n",
    "    job_title = aTag.get('title')\n",
    "    \n",
    "    #job_url = 'https://www.indeed.com' + aTag.get('href')\n",
    "    job_url = 'https://www.indeed.com/viewjob?jk=' + job_id\n",
    "    post_response = requests.get(job_url)\n",
    "    post_soup = BeautifulSoup(post_response.text, 'html.parser')\n",
    "    try:\n",
    "        job_description = post_soup.find('div','jobsearch-jobDescriptionText').text.strip()\n",
    "    except AttributeError:\n",
    "        job_description =''\n",
    "        \n",
    "    try:\n",
    "        job_detail = post_soup.find('div','jobsearch-JobDescriptionSection-section').text.strip()\n",
    "    except AttributeError:\n",
    "        job_detail = ''\n",
    "    \n",
    "    job_company = card.find('span','company').text.strip()\n",
    "    job_location = card.find('div', 'recJobLoc').get('data-rc-loc')\n",
    "    job_summary = card.find('div', 'summary').text.strip()\n",
    "    job_post_date = card.find('span','date').text.strip()\n",
    "    \n",
    "    # optional variables\n",
    "    try:\n",
    "        company_rating = card.find('span','ratingsContent').text.strip()\n",
    "    except AttributeError:\n",
    "        company_rating = ''\n",
    "        \n",
    "    try:\n",
    "        job_salary = card.find('span','salaryText').text.strip()\n",
    "    except AttributeError:\n",
    "        job_salary = ''\n",
    "    \n",
    "    try:\n",
    "        job_remote = card.find('span','remote').text.strip()\n",
    "    except AttributeError:\n",
    "        job_remote = ''\n",
    "        \n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    record = (job_id, job_title,job_company,job_location,company_rating, job_post_date,today,job_summary,job_salary, job_remote, job_url, job_description, job_detail)\n",
    "    \n",
    "    return record\n",
    "\n",
    "def main(position, postedDay, fileName):\n",
    "    \"\"\"Run the main program routine\"\"\"\n",
    "    records = []\n",
    "    url = get_job_search_url(position, postedDay)\n",
    "\n",
    "    # extract the job data\n",
    "    while True:        \n",
    "        print(url)\n",
    "       \n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        if soup.title.text.find('Captcha') != -1: \n",
    "            print('blocked by Captcha!')\n",
    "            break\n",
    "            \n",
    "        cards = soup.find_all('div', 'jobsearch-SerpJobCard')        \n",
    "        total_jobs = soup.find('div',{'id':'searchCountPages'}).text.strip()\n",
    "        print(len(cards), total_jobs)\n",
    "        \n",
    "        for card in cards:\n",
    "            record = get_record(card)\n",
    "            records.append(record)\n",
    "            time.sleep(3)\n",
    "   \n",
    "        try:\n",
    "            url = 'https://www.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href') \n",
    "        except AttributeError:     \n",
    "            print('done!')\n",
    "            break\n",
    "            \n",
    "        #time.sleep(60)\n",
    "        \n",
    "    print(position + ': '+ str(len(records)))\n",
    "    # save the job data\n",
    "    if (len(records) > 0):\n",
    "        with open('../data/raw/'+fileName+datetime.today().strftime('%Y_%m_%d_%H_%M_%S')+ '.csv', 'w', newline ='', encoding ='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['JobID', 'JobTitle', 'Company','Location', 'CompanyRating', 'PostDate', 'ExtractDate','Summary', 'Salary', 'Remote','JobUrl','JobDescription', 'JobDetail'])\n",
    "            writer.writerows(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1: Indeed will not return exactly amount of jobs shown on the pagination based on some internal filtering they run, unless you add query string &filter = 0 in the url. \n",
    "https://www.indeed.com/jobs?q=machine+learning&fromage=1&filter=0&start=200\n",
    "\n",
    "2: Added some sleep time to avoid being blocked by CAPTCHA\n",
    "\n",
    "3: blocked by Captcha after scraping around 1k , 1073/3463  with sleep time(3) (5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=data science, data scientist&fromage=1&limit=50\n",
      "blocked by Captcha!\n",
      "data science, data scientist: 0\n"
     ]
    }
   ],
   "source": [
    "# run the main program\n",
    "#main('data scientist', 7 ,'ds_last7d_')\n",
    "#main('machine learning', 7, 'ml_last7d_')\n",
    "#main('data analyst', 7 , 'dat_last7d_')\n",
    "#main('data analytics', 7, 'das_last7d_')\n",
    "\n",
    "main('data science, data scientist',1 ,'ds_last1d_')      # < 2,000 result per day\n",
    "#main('data analytics, data analyst',1 ,'ds_last1d_')     # < 2,000 result per day\n",
    "#main('machine learning', 3 ,'ml_last1d_')     # <2,000 result  per 3 days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div','h-captcha')\n",
    "soup.title.text.find('Captcha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocked by Captcha!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if soup.title.text.find('Captcha') != -1: print('blocked by Captcha!')\n",
    "len(records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
