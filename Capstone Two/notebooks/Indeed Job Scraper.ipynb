{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a general purpose job scraper for www.indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_search_url(position, postedDays):\n",
    "    \"\"\"Generate a url from position and posted days ago\"\"\"\n",
    "\n",
    "    template = 'https://www.indeed.com/jobs?q={}&fromage={}&limit=50&filter=0'\n",
    "    url=template.format(position, postedDays)\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_job_search_url('machine learning', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Extract raw html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page 1 of 546 jobs'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_jobs = soup.find('div',{'id':'searchCountPages'}).text.strip()\n",
    "total_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = soup.find_all('div', 'jobsearch-SerpJobCard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype the model with a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "card = cards[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "aTag = card.h2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = aTag.get('title')\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2a073aaa41c0c83f'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_id = card.get('data-jk')\n",
    "job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check if the card already stored in the records  # 517da30c1f7ab5f0\n",
    "type(records)\n",
    "records_ar = np.array(records)\n",
    "#'517da30c1f7ab5f0' in np.array(records)\n",
    "'517da30c1f7ab5f0' in np.array(records)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(60)\n",
    "job_url = 'https://www.indeed.com' + aTag.get('href')\n",
    "job_url\n",
    "\n",
    "post_response = requests.get(job_url)\n",
    "post_soup = BeautifulSoup(post_response.text, 'html.parser')\n",
    "job_description = post_soup.find('div','jobsearch-jobDescriptionText').text.strip()\n",
    "job_description\n",
    "\n",
    "try:\n",
    "    job_detail = post_soup.find('div','jobsearch-JobDescriptionSection-section').text.strip()\n",
    "except:\n",
    "    job_detail = ''\n",
    "job_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tradeweb is looking to add a Data Scientist to its Data & Analytics team. Our Data Science team is responsible for managing the development and optimization of advanced analytics on a global scale across the company.\\nIn this role, you will enjoy working with one of the richest financial data sets in the world, cutting edge technology, and the ability to see your insights turned into real products on a regular basis. The ideal candidate will have experience doing advanced data analysis, will have worked with large data stores, and will have experience building machine learning models. Candidates should be curious, focused on results, a self-starter, and have demonstrated success in using analytics to drive value in an organization.\\nDesign, build, test and deliver new data science services and advanced analytics to Tradeweb globally\\nDevelop scalable tools leveraging machine learning and/or deep learning models to solve real-world problems in areas such as time series predictions\\nSuggest, collect and synthesize requirements to create an effective roadmap towards the deployment of production-level machine learning applications\\nMaintain, improve and deliver innovations to the existing data products used\\nInvestigate ad hoc issues and debugging regressions\\nContribute to testing plans and validate statistically accurate results\\nAnalyze data trends to identify opportunities for growth\\nPartner with Data Engineering to ensure the right metrics are created and validate accuracy\\nValidate metric accuracy for internal and external reporting\\nMinimum Qualifications:\\nMasterâ€™s Degree or PhD in a quantitative field (Computer Science, Data Science, Statistics, Operations Research, Machine Learning or Economics) or equivalent work experience\\n3+ years of experience working in data science at a financial, technology or media firm\\nSignificant experience and expertise with probability and statistics, inclusive of machine learning, experimental design, and optimization\\nHighly skilled in scripting languages and have rapid prototyping skills, like SQL, Python, Perl, Java, among others\\nTeam builder, results oriented, and proactive\\nAbout Tradeweb:\\nTradeweb Markets Inc. (NASDAQ: TW) is a leading, global operator of electronic marketplaces for rates, credit, equities and money markets. Founded in 1996, Tradeweb provides access to markets, data and analytics, electronic trading, straight-through-processing and reporting for clients in the institutional, wholesale and retail markets. Advanced technologies developed by Tradeweb enhance price discovery, order execution and trade workflows while allowing for greater scale and helping to reduce risks in client trading operations. For more information, please go to www.tradeweb.com .\\nTradeweb Markets LLC (\"Tradeweb\") is proud to be an EEO Minorities/Females/Protected Veterans/Disabled/Affirmative Action Employer.\\nhttps://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oxford Global Resources'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_company = card.find('span','company').text.strip()\n",
    "job_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    company_rating = card.find('span','ratingsContent').text.strip()\n",
    "except AttributeError:\n",
    "    company_rating = ''\n",
    "company_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remote'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_location = card.find('div', 'recJobLoc').get('data-rc-loc')\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scientists will participate in data model development and petabyte-level data process optimization.\\nSome experience in big data processing.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_summary = card.find('div', 'summary').text.strip()\n",
    "job_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_post_date = card.find('span','date').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today().strftime('%Y-%m-%d') # To do: need to add time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021_02_14_20_13_19'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today().strftime('%Y_%m_%d_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 2, 14, 20, 13, 19, 452396)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    job_salary = card.find('span','salaryText').text.strip()\n",
    "except AttributeError:\n",
    "    job_salary = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    job_remote = card.find('span','remote').text.strip()\n",
    "except AttributeError:\n",
    "    job_remote = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalize the model with a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(card, withDetail):\n",
    "    \"\"\"Extract individual job post data from a single record \"\"\"\n",
    "    # required variables\n",
    "    job_id = card.get('data-jk')\n",
    "    aTag = card.h2.a\n",
    "    job_title = aTag.get('title')\n",
    "    \n",
    "    #job_url = 'https://www.indeed.com' + aTag.get('href')\n",
    "    job_url = 'https://www.indeed.com/viewjob?jk=' + job_id\n",
    "    \n",
    "    if withDetail:\n",
    "        post_response = requests.get(job_url)\n",
    "        post_soup = BeautifulSoup(post_response.text, 'html.parser')\n",
    "        try:\n",
    "            job_description = post_soup.find('div','jobsearch-jobDescriptionText').text.strip()\n",
    "        except AttributeError:\n",
    "            job_description = ''       \n",
    "\n",
    "        try:\n",
    "            job_detail = post_soup.find('div','jobsearch-JobDescriptionSection').text.strip()\n",
    "        except AttributeError:\n",
    "            job_detail = ''\n",
    "    \n",
    "    job_company = card.find('span','company').text.strip()\n",
    "    job_location = card.find('div', 'recJobLoc').get('data-rc-loc')\n",
    "    job_summary = card.find('div', 'summary').text.strip()\n",
    "    job_post_date = card.find('span','date').text.strip()\n",
    "    \n",
    "    # optional variables\n",
    "    try:\n",
    "        company_rating = card.find('span','ratingsContent').text.strip()\n",
    "    except AttributeError:\n",
    "        company_rating = ''\n",
    "    \n",
    "    try:\n",
    "        job_salary = card.find('span','salaryText').text.strip()\n",
    "    except AttributeError:\n",
    "        job_salary = ''\n",
    "    \n",
    "    try:\n",
    "        job_remote = card.find('span','remote').text.strip()\n",
    "    except AttributeError:\n",
    "        job_remote = ''\n",
    "        \n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    if withDetail:\n",
    "        record = (job_id, job_title,job_company,job_location,company_rating, job_post_date,today,job_summary,job_salary, job_remote, job_url, job_detail, job_description)\n",
    "    else:\n",
    "        record = (job_id, job_title,job_company,job_location,company_rating, job_post_date,today,job_summary,job_salary, job_remote, job_url)\n",
    "   \n",
    "    return record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "records = []\n",
    "\n",
    "for card in cards:\n",
    "    if records == []:\n",
    "        record = get_record(card, withDetail = True)\n",
    "        records.append(record)\n",
    "    else:\n",
    "        #To check if the card is already stored in the records\n",
    "        id_array = np.array([r[0] for r in records])\n",
    "        if not card.get('data-jk') in id_array:   \n",
    "            record = get_record(card, withDetail = True)\n",
    "            records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['51d2ea04d15fbf1f', '571e360548a8d0c1', '2f143848e64c0573',\n",
       "        '32e4ffa91d91f8ed', '517da30c1f7ab5f0', 'eb71688408d695be',\n",
       "        'd2a2d1dba9456a6d', 'd080318aa423d790', '558379216e05a524',\n",
       "        'd9c74d0d57cd11f2', '9bfea2a8b8774194', 'e874bf89e3161b17',\n",
       "        'a078eabd7f5b3f38', '1145d029b0d268ae'], dtype='<U10786'),\n",
       " 15)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_array, len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(records[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the next page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>hCaptcha solve page</title>\n",
       "<script async=\"\" defer=\"\" src=\"https://www.hcaptcha.com/1/api.js\"></script>\n",
       "</head>\n",
       "<body>\n",
       "<form action=\"/jobs?q=machine+learning&amp;fromage=1&amp;start=120\" method=\"POST\">\n",
       "<div class=\"h-captcha\" data-sitekey=\"eb27f525-f936-43b4-91e2-95a426d4a8bd\"></div>\n",
       "<br/>\n",
       "<input type=\"submit\" value=\"Submit\"/>\n",
       "</form>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=machine learning&fromage=1&limit=50&filter=0\n",
      "https://www.indeed.com/jobs?q=machine learning&fromage=1&limit=50&filter=0\n",
      "55\n",
      "55\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=50\n",
      "55\n",
      "110\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=100\n",
      "55\n",
      "165\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=150\n",
      "55\n",
      "220\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=200\n",
      "55\n",
      "275\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=250\n",
      "55\n",
      "330\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=300\n",
      "54\n",
      "384\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=350\n",
      "55\n",
      "439\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=400\n",
      "55\n",
      "494\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=450\n",
      "54\n",
      "548\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=500\n",
      "55\n",
      "603\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=550\n",
      "55\n",
      "658\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=600\n",
      "54\n",
      "712\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=650\n",
      "55\n",
      "767\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=700\n",
      "54\n",
      "821\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=750\n",
      "55\n",
      "876\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=800\n",
      "55\n",
      "931\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=850\n",
      "29\n",
      "960\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=850\n",
      "Page 18 of 875 jobs\n",
      "960\n"
     ]
    }
   ],
   "source": [
    "records =[]\n",
    "url = get_job_search_url('machine learning', 1)\n",
    "print( url )\n",
    "while True:\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')   \n",
    "    cards = soup.find_all('div', 'jobsearch-SerpJobCard')\n",
    "    print(len(cards))\n",
    " \n",
    "    '''for card in cards:\n",
    "        record = get_record(card, withDetail = False)\n",
    "        records.append(record)\n",
    "        #time.sleep(3)'''\n",
    "        \n",
    "    for card in cards:\n",
    "        if records == []:\n",
    "            record = get_record(card, withDetail = True)\n",
    "            records.append(record)\n",
    "        else:\n",
    "            #To check if the card is already stored in the records\n",
    "            id_array = np.array([r[0] for r in records])\n",
    "            if not card.get('data-jk') in id_array:   \n",
    "                record = get_record(card, withDetail = False)\n",
    "                records.append(record)\n",
    "\n",
    "    print(len(records))\n",
    "    if len(cards)> 0:\n",
    "        try:\n",
    "            url = 'https://www.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href')\n",
    "        except AttributeError:\n",
    "            total_jobs = soup.find('div',{'id':'searchCountPages'}).text.strip()\n",
    "            print(url)\n",
    "            print(total_jobs)\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    else: break\n",
    "        \n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['589dfaeb201f6431', '8e330e086b957051'], dtype='<U16')"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([r[0] for r in records])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-cb4ebf620f7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'aria-label'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Next'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "soup.find('a', {'aria-label': 'Next'}).get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "def get_job_search_url(position, postedDays):\n",
    "    \"\"\"Generate a url from position and posted days ago\n",
    "    with 50 job posts per page and no filter\"\"\"\n",
    "\n",
    "    template = 'https://www.indeed.com/jobs?q={}&fromage={}&limit=50&filter=0'\n",
    "    url=template.format(position, postedDays)\n",
    "    \n",
    "    return url\n",
    "\n",
    "def get_record(card, withDetail=False):\n",
    "    \"\"\"Extract individual job post data from a single record to create a tuple record\n",
    "    with option to get detail job description \"\"\"\n",
    "    \n",
    "    # required variables\n",
    "    job_id = card.get('data-jk')\n",
    "    aTag = card.h2.a\n",
    "    job_title = aTag.get('title')\n",
    "    \n",
    "    #job_url = 'https://www.indeed.com' + aTag.get('href')\n",
    "    job_url = 'https://www.indeed.com/viewjob?jk=' + job_id\n",
    "    \n",
    "    if withDetail:\n",
    "        post_response = requests.get(job_url)\n",
    "        post_soup = BeautifulSoup(post_response.text, 'html.parser')\n",
    "        try:\n",
    "            job_description = post_soup.find('div','jobsearch-jobDescriptionText').text.strip()\n",
    "        except AttributeError:\n",
    "            job_description = ''       \n",
    "\n",
    "        try:\n",
    "            job_detail = post_soup.find('div','jobsearch-JobDescriptionSection').text.strip()\n",
    "        except AttributeError:\n",
    "            job_detail = ''\n",
    "    \n",
    "    job_company = card.find('span','company').text.strip()\n",
    "    job_location = card.find('div', 'recJobLoc').get('data-rc-loc')\n",
    "    job_summary = card.find('div', 'summary').text.strip()\n",
    "    job_post_date = card.find('span','date').text.strip()\n",
    "    \n",
    "    # optional variables\n",
    "    try:\n",
    "        company_rating = card.find('span','ratingsContent').text.strip()\n",
    "    except AttributeError:\n",
    "        company_rating = ''\n",
    "    \n",
    "    try:\n",
    "        job_salary = card.find('span','salaryText').text.strip()\n",
    "    except AttributeError:\n",
    "        job_salary = ''\n",
    "    \n",
    "    try:\n",
    "        job_remote = card.find('span','remote').text.strip()\n",
    "    except AttributeError:\n",
    "        job_remote = ''\n",
    "        \n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Create tuple of each job posting record\n",
    "    if withDetail:\n",
    "        record = (job_id, job_title,job_company,job_location,company_rating, job_post_date,today,job_summary,job_salary, job_remote, job_url, job_detail, job_description)\n",
    "    else:\n",
    "        record = (job_id, job_title,job_company,job_location,company_rating, job_post_date,today,job_summary,job_salary, job_remote, job_url)\n",
    "   \n",
    "    return record\n",
    "\n",
    "def main(position, postedDay, fileName, withDetail):\n",
    "    \"\"\"Run the main program routine\"\"\"\n",
    "    records = []\n",
    "    url = get_job_search_url(position, postedDay)\n",
    "\n",
    "    # extract the job data\n",
    "    while True:        \n",
    "        print(url)\n",
    "       \n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        if soup.title.text.find('Captcha') != -1: \n",
    "            print('blocked by Captcha!')\n",
    "            break\n",
    "            \n",
    "        cards = soup.find_all('div', 'jobsearch-SerpJobCard')        \n",
    "        total_jobs = soup.find('div',{'id':'searchCountPages'}).text.strip()\n",
    "        print(len(cards), total_jobs)\n",
    "        \n",
    "           \n",
    "        for card in cards:\n",
    "            if records == []:\n",
    "                record = get_record(card, withDetail)\n",
    "                records.append(record)\n",
    "            else:\n",
    "                #To check if the card is already stored in the records to reduce the duplicate records\n",
    "                id_array = np.array([r[0] for r in records])\n",
    "                if not card.get('data-jk') in id_array:   \n",
    "                    record = get_record(card, withDetail)\n",
    "                    records.append(record)\n",
    "   \n",
    "        try:\n",
    "            url = 'https://www.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href') \n",
    "        except AttributeError:     \n",
    "            print('done!')\n",
    "            break\n",
    "            \n",
    "        #time.sleep(60)\n",
    "        \n",
    "   \n",
    "    firstRow ='{0}: {1} {2}'.format('test', str(len(records)),total_jobs[total_jobs.index('of'):])\n",
    "    print(firstRow)\n",
    "    # save the job data\n",
    "    if (len(records) > 0):\n",
    "        if withDetail: \n",
    "            fn = '../data/raw/{0}{1}_W.csv'.format(fileName,datetime.today().strftime('%Y_%m_%d'))\n",
    "        else: \n",
    "            fn = '../data/raw/{0}{1}.csv'.format(fileName,datetime.today().strftime('%Y_%m_%d'))\n",
    "            \n",
    "        with open(fn, 'w', newline ='', encoding ='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(firstRow)\n",
    "            if withDetail:\n",
    "                writer.writerow(['JobID', 'JobTitle', 'Company','Location', 'CompanyRating', 'PostDate', 'ExtractDate','Summary', 'Salary', 'Remote','JobUrl','JobDetail', 'JobDescription'])\n",
    "            else:\n",
    "                writer.writerow(['JobID', 'JobTitle', 'Company','Location', 'CompanyRating', 'PostDate', 'ExtractDate','Summary', 'Salary', 'Remote','JobUrl'])\n",
    "            writer.writerows(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1: Indeed will not return exactly amount of jobs shown on the pagination based on some internal filtering they run, unless you add query string &filter = 0 in the url.  With the filter, it will still only can get to 20*50 =1000 records \n",
    "https://www.indeed.com/jobs?q=machine+learning&fromage=1&filter=0&start=200\n",
    "\"We have removed 2,463 job postings very similar to those already shown. To see these additional results, you may repeat your search with the omitted job postings included.\" \n",
    "\n",
    "2: Every midnight, run program for 3 search criterion without job detailed description for 1 day posting without filter\n",
    "Observesd: the maximum number of records Indeed allow to get is 50 * 20 = 1000\n",
    "\n",
    "3: With job detailed description, need to added some sleep time to avoid being blocked by CAPTCHA\n",
    "Also, need to come up some algorithm to random sample the detailed job description, considering only scrape it of remote jobs\n",
    "\n",
    "\n",
    "4: sometimes may encounter connection broken from Request\n",
    "\n",
    "To do list:\n",
    "1: To add scheduler \n",
    "2: To add algorithm for random sampling for detailed job description \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=data science, data scientist&fromage=1&limit=50&filter=0\n",
      "57 Page 1 of 4,704 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=50\n",
      "56 Page 2 of 4,704 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=100\n",
      "56 Page 3 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=150\n",
      "55 Page 4 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=200\n",
      "56 Page 5 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=250\n",
      "55 Page 6 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=300\n",
      "55 Page 7 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=350\n",
      "55 Page 8 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=400\n",
      "55 Page 9 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=450\n",
      "55 Page 10 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=500\n",
      "55 Page 11 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=550\n",
      "57 Page 12 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=600\n",
      "56 Page 13 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=650\n",
      "55 Page 14 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=700\n",
      "55 Page 15 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=750\n",
      "54 Page 16 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=800\n",
      "55 Page 17 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=850\n",
      "58 Page 18 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=900\n",
      "56 Page 19 of 4,562 jobs\n",
      "https://www.indeed.com/jobs?q=data+science%2C+data+scientist&limit=50&fromage=1&filter=0&start=950\n",
      "55 Page 20 of 4,562 jobs\n",
      "done!\n",
      "data science, data scientist: 1111\n",
      "https://www.indeed.com/jobs?q=data analytics, data analyst&fromage=1&limit=50&filter=0\n",
      "55 Page 1 of 4,529 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=50\n",
      "55 Page 2 of 4,529 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=100\n",
      "55 Page 3 of 4,529 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=150\n",
      "55 Page 4 of 4,529 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=200\n",
      "54 Page 5 of 4,529 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=250\n",
      "56 Page 6 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=300\n",
      "56 Page 7 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=350\n",
      "55 Page 8 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=400\n",
      "55 Page 9 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=450\n",
      "56 Page 10 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=500\n",
      "55 Page 11 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=550\n",
      "55 Page 12 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=600\n",
      "56 Page 13 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=650\n",
      "55 Page 14 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=700\n",
      "56 Page 15 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=750\n",
      "55 Page 16 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=800\n",
      "56 Page 17 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=850\n",
      "55 Page 18 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=900\n",
      "55 Page 19 of 4,672 jobs\n",
      "https://www.indeed.com/jobs?q=data+analytics%2C+data+analyst&limit=50&fromage=1&filter=0&start=950\n",
      "55 Page 20 of 4,672 jobs\n",
      "done!\n",
      "data analytics, data analyst: 1105\n",
      "https://www.indeed.com/jobs?q=machine learning&fromage=1&limit=50&filter=0\n",
      "54 Page 1 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=50\n",
      "53 Page 2 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=100\n",
      "55 Page 3 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=150\n",
      "55 Page 4 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=200\n",
      "55 Page 5 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=250\n",
      "55 Page 6 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=300\n",
      "55 Page 7 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=350\n",
      "54 Page 8 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=400\n",
      "54 Page 9 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=450\n",
      "55 Page 10 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=500\n",
      "55 Page 11 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=550\n",
      "55 Page 12 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=600\n",
      "54 Page 13 of 663 jobs\n",
      "https://www.indeed.com/jobs?q=machine+learning&limit=50&fromage=1&filter=0&start=650\n",
      "17 Page 14 of 663 jobs\n",
      "done!\n",
      "machine learning: 726\n"
     ]
    }
   ],
   "source": [
    "# run the main program\n",
    "#main('data scientist', 7 ,'ds_last7d_')\n",
    "#main('machine learning', 7, 'ml_last7d_')\n",
    "#main('data analyst', 7 , 'dat_last7d_')\n",
    "#main('data analytics', 7, 'das_last7d_')\n",
    "\n",
    "# without detailed job description  #with filter =0 # with no sleep time\n",
    "time.sleep(10000)\n",
    "main('data science, data scientist',1 ,'ds_last1d_', withDetail= False) \n",
    "\n",
    "main('data analytics, data analyst',1 ,'da_last1d_', withDetail= False)     \n",
    "\n",
    "main('machine learning', 1 ,'ml_last1d_', withDetail= False)   \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "# add discription \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div','h-captcha')\n",
    "soup.title.text.find('Captcha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocked by Captcha!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if soup.title.text.find('Captcha') != -1: print('blocked by Captcha!')\n",
    "len(records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
